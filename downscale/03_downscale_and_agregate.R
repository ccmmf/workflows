#' ---
#' Title: Downscale and Agregate Woody Crop SOC stocks
#' author: "David LeBauer"
#' ---
#' 
## ----setup--------------------------------------------------------------------
#remotes::install_github("dlebauer/pecan@ensemble_downscaling", subdir = "modules/assim.sequential", ref = "da96331")
library(tidyverse)
library(sf)
library(terra)

library(PEcAnAssimSequential)

#' 
#' # Overview
#' 
#' This workflow will:
#' 
#' - Use environmental covariates to predict SIPNET estimated SOC for each woody crop field in the LandIQ dataset
#'   - Uses Random Forest [maybe change to CNN later] trained on site-scale model runs.
#'   - Build a model for each ensemble member
#' - Write out a table with predicted biomass and SOC to maintain ensemble structure, ensuring correct error propagation and spatial covariance.
#' - Aggregate County-level biomass and SOC inventories
#' 
#' ## Get Site Level Outputs
#' 
#' Here we we read in a table with site-level model outputs generated by SIPNETWOPET in 02_anchorsite_simulations.qmd.
#' 
#' TODO:
#' - replace SIPNETWOPET outputs with SIPNET results
#' 
## -----------------------------------------------------------------------------
sipnetwopet_output <- read_csv("cache/sipnetwopet_design_point_results.csv")

ensemble_data <- readRDS("cache/ensemble_data.rds")




#' 
#' ### Random Forest using PEcAn downscale workflow
#' 
#' 
## -----------------------------------------------------------------------------
site_attributes <- readr::read_csv("data/ca_field_attributes.csv") |>
  filter(id %in% site_ids)


covariates <- load("data/data_for_clust_with_ids.rda") |>
  get() # maybe there is a less convoluted way; maybe I just need to rename data_for_clust...

covariates_points <- design_points |> left_join(covariates, by = "id")
covariates_vect <- covariates_points |>
  vect(geom = c("lon", "lat"), crs = "EPSG:4326")

raster::stack(

)
downscale_output <- SDA_downscale(
  preprocessed = preprocessed,
  date = "2020-01-01",
  carbon_pool = "SOC",
  covariates = covariates_stack,  # replace with your covariates SpatRaster stack
  model_type = "rf",  # or "cnn" for Convolutional Neural Network
  seed = 123
)

metrics <- SDA_downscale_metrics(downscale_output, carbon_pool = "SOC")
print(metrics)

#' 
#' 
#' ## Aggregate to County Level
#' 
## -----------------------------------------------------------------------------
library(sf)
library(dplyr)

# Load CA county boundaries
# These are provided by Cal-Adapt as 'Areas of Interest'
county_boundaries <- st_read("data/counties.gpkg")

# check if attributes has county name
# Append county name to predicted table
grid_with_counties <- st_join(ca_grid, county_boundaries, join = st_intersects)

# Calculate county-level mean, median, and standard deviation.
county_aggregates <- grid_with_counties  |>
  st_drop_geometry()  |>   # drop geometry for faster summarization
  group_by(county_name)  |>   # replace with your actual county identifier
  summarize(
    mean_biomass   = mean(predicted_biomass, na.rm = TRUE),
    median_biomass = median(predicted_biomass, na.rm = TRUE),
    sd_biomass     = sd(predicted_biomass, na.rm = TRUE)
  )

print(county_aggregates)

# For state-level, do the same but don't group_by county

#' ````
